{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFTxgQSXQcJb"
   },
   "source": [
    "# Permutation models for Bayesian Performance Analysis\n",
    "\n",
    "In this notebook we implement several probabilistic models on permutations to be used in a Bayesian inference framework for performance analysis. The notebook is divided in the following sections:\n",
    "\n",
    "* Preliminaries section installs and configures all the dependendencies required by the notebook.\n",
    "* Syntetic Data section contains a few tests of the Bayesian analysis carried out using syntetically generated permutation datasets.\n",
    "* EDA FSP Data section contains a Bayesian analysis carried out using real data comming from the comparison of several algorithms on several instances of the FlowShop Schedule Problem. See Ceberio et. al. [1] for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_anERYeKfI8"
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxukXJ8gqUs2"
   },
   "source": [
    "### Install pre-requisites\n",
    "\n",
    "* BallesMallows: an R package\n",
    "* Bayes Perm: our Pyhon package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmC9p4Xvqfp-"
   },
   "source": [
    "#### Install BayesMallows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3mi0lMiFksw"
   },
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects.packages as rpackages\n",
    "import rpy2.robjects.numpy2ri\n",
    "\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3UvEi-SDJ4z"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install libmpfr-dev -qq > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvV5qu9XHYhW"
   },
   "outputs": [],
   "source": [
    "rpy2.robjects.numpy2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54_htvZzAeMp"
   },
   "outputs": [],
   "source": [
    "!chmod -R 777 /usr/local/lib/R/site-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrfi3junrtvj"
   },
   "outputs": [],
   "source": [
    "utils = rpackages.importr('utils')\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "utils.install_packages('BayesMallows', verbose=False, quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nQ44nPXqjMA"
   },
   "source": [
    "#### Install BayesPerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycY7k-ryqmYD"
   },
   "outputs": [],
   "source": [
    "!pip install BayesPermus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olgSO1JVqL8v"
   },
   "source": [
    "### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJa-SxuZqQQJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abe14iNj3Xqe"
   },
   "outputs": [],
   "source": [
    "from BayesPermus.models.PlackettLuce import PlackettLuceDirichlet\n",
    "from BayesPermus.models.PlackettLuce import PlackettLuceGamma\n",
    "from BayesPermus.models.BradleyTerry import BradleyTerry\n",
    "from BayesPermus.models.MallowsModel import MallowsModel\n",
    "from BayesPermus.figure.plot import Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDrNY-7Bz2iL"
   },
   "source": [
    "## Case of study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qm3_SsZdz6jV"
   },
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ls9oVkvOfRp"
   },
   "source": [
    "#### Functions to calculate the marginal probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Pvw7deM2ov_"
   },
   "outputs": [],
   "source": [
    "def calculate_top_ranking_probs(orderings, num_samples=1000):\n",
    "  num_instances, num_algorithms = orderings.shape\n",
    "\n",
    "  # PL Dirichlet hyper-priors\n",
    "  dirichlet_alpha_pl = num_algorithms * [1]\n",
    "\n",
    "  # PL Gamma hyper-priors\n",
    "  gamma_alpha_pl = 0.5\n",
    "  gamma_beta_pl = 0.5\n",
    "\n",
    "  # BT Dirichlet hyper-priors\n",
    "  dirichlet_alpha_bt = num_algorithms * [1]\n",
    "\n",
    "  placettLuceDirichlet = PlackettLuceDirichlet(dirichlet_alpha_pl, num_samples=num_samples)\n",
    "  placettLuceGamma = PlackettLuceGamma(gamma_alpha_pl, gamma_beta_pl, num_samples=num_samples)\n",
    "  bradleyTerry = BradleyTerry(dirichlet_alpha_bt, num_samples=num_samples)\n",
    "  mallowsModel = MallowsModel(num_samples=num_samples)\n",
    "\n",
    "  pld = placettLuceDirichlet.calculate_top_ranking_probs(orderings)\n",
    "  plg = placettLuceGamma.calculate_top_ranking_probs(orderings)\n",
    "  bt  = bradleyTerry.calculate_top_ranking_probs(orderings)\n",
    "  mm  = mallowsModel.calculate_top_ranking_probs(orderings)\n",
    "\n",
    "  return pld, plg, bt, mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fs5clNHSeS3q"
   },
   "outputs": [],
   "source": [
    "def calculate_better_than_probs(orderings, num_samples=1000):\n",
    "  num_instances, num_algorithms = orderings.shape\n",
    "\n",
    "  # PL Dirichlet hyper-priors\n",
    "  dirichlet_alpha_pl = num_algorithms * [1]\n",
    "\n",
    "  # PL Gamma hyper-priors\n",
    "  gamma_alpha_pl = 0.5\n",
    "  gamma_beta_pl = 0.5\n",
    "\n",
    "  # BT Dirichlet hyper-priors\n",
    "  dirichlet_alpha_bt = num_algorithms * [1]\n",
    "\n",
    "  placettLuceDirichlet = PlackettLuceDirichlet(dirichlet_alpha_pl, num_samples=num_samples)\n",
    "  placettLuceGamma = PlackettLuceGamma(gamma_alpha_pl, gamma_beta_pl, num_samples=num_samples)\n",
    "  bradleyTerry = BradleyTerry(dirichlet_alpha_bt, num_samples=num_samples)\n",
    "  mallowsModel = MallowsModel(num_samples=num_samples)\n",
    "\n",
    "  pld = placettLuceDirichlet.calculate_better_than_probs(orderings)\n",
    "  plg = placettLuceGamma.calculate_better_than_probs(orderings)\n",
    "  bt  = bradleyTerry.calculate_better_than_probs(orderings)\n",
    "  mm  = mallowsModel.calculate_better_than_probs(orderings)\n",
    "\n",
    "  return pld, plg, bt, mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbRO8Xta2h8P"
   },
   "outputs": [],
   "source": [
    "def calculate_top_k_probs(orderings, num_samples=1000):\n",
    "  num_instances, num_algorithms = orderings.shape\n",
    "\n",
    "  # PL Dirichlet hyper-priors\n",
    "  dirichlet_alpha_pl = num_algorithms * [1]\n",
    "\n",
    "  # PL Gamma hyper-priors\n",
    "  gamma_alpha_pl = 0.5\n",
    "  gamma_beta_pl = 0.5\n",
    "\n",
    "  # BT Dirichlet hyper-priors\n",
    "  dirichlet_alpha_bt = num_algorithms * [1]\n",
    "\n",
    "  placettLuceDirichlet = PlackettLuceDirichlet(dirichlet_alpha_pl, num_samples=num_samples)\n",
    "  placettLuceGamma = PlackettLuceGamma(gamma_alpha_pl, gamma_beta_pl, num_samples=num_samples)\n",
    "  bradleyTerry = BradleyTerry(dirichlet_alpha_bt, num_samples=num_samples)\n",
    "  mallowsModel = MallowsModel(num_samples=num_samples)\n",
    "\n",
    "  pld = placettLuceDirichlet.calculate_top_k_probs(orderings)\n",
    "  plg = placettLuceGamma.calculate_top_k_probs(orderings)\n",
    "  bt  = bradleyTerry.calculate_top_k_probs(orderings)\n",
    "  mm  = mallowsModel.calculate_top_k_probs(orderings)\n",
    "\n",
    "  return pld, plg, bt, mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrR1gqx_OlCL"
   },
   "source": [
    "#### Functions to plot the marginal probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4RC6s3Q2-9o"
   },
   "outputs": [],
   "source": [
    "def plot_top_ranking_probs(fig_name, model_names, algorithm_names, probs, empirical):\n",
    "  plotter = Plot()\n",
    "  num_samples, num_algorithms = probs[0].shape\n",
    "  fig = plt.figure()\n",
    "  fig, axs = plt.subplots(1, num_algorithms, figsize=(4 * num_algorithms, 2), sharey=True)\n",
    "\n",
    "  plotter.plot_top_ranking_probs(model_names, algorithm_names, probs, empirical, axs)\n",
    "  fig.savefig(fig_name + \".pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgoURw4FebSd"
   },
   "outputs": [],
   "source": [
    "def plot_better_than_probs(fig_name, model_names, algorithm_names, probs, empirical):\n",
    "  plotter = Plot()\n",
    "  num_samples, num_algorithms, _ = probs[0].shape\n",
    "  fig = plt.figure()\n",
    "  fig, axs = plt.subplots(len(model_names), num_algorithms, figsize=(4 * num_algorithms, 2 * len(model_names)), sharey=True)\n",
    "\n",
    "  plotter.plot_better_than_probs(model_names, algorithm_names, probs, empirical, axs)\n",
    "  fig.savefig(fig_name + \".pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4nfuv4pJT0H"
   },
   "outputs": [],
   "source": [
    "def plot_better_than_polar(num_algorithms, algorithm_names, probs):\n",
    "  fig, axs = plt.subplots(1, num_algorithms - 1, figsize=((num_algorithms - 1) * 5, 4), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "  for i in range(num_algorithms - 1):\n",
    "    ax = axs[i]\n",
    "\n",
    "    minor = []\n",
    "    major = []\n",
    "    labels =  []\n",
    "\n",
    "    for j in range(i + 1, num_algorithms):\n",
    "      start = 2 * np.pi * (j - i - 1) / (num_algorithms - i - 1)\n",
    "      end = start + 2 * np.pi / (num_algorithms - i - 1)\n",
    "\n",
    "      major.append(start)\n",
    "      minor.append((end + start) / 2)\n",
    "      labels.append(algorithm_names[j])\n",
    "      major.append(end)\n",
    "\n",
    "    ax.set_xticks(major)\n",
    "    ax.set_xticks(minor, minor=True)\n",
    "    ax.set_xticklabels(labels, minor=True)\n",
    "    ax.set_xticklabels([], minor=False)\n",
    "\n",
    "    ax.text(0, 0, algorithm_names[i], ha='center',va='center')\n",
    "    ax.grid(which='minor', alpha=0.2)\n",
    "    ax.grid(which='major', alpha=1, linewidth=2)\n",
    "\n",
    "\n",
    "    for j in range(i + 1, num_algorithms):\n",
    "      p = probs[:, i, j]\n",
    "      start = 2 * np.pi * (j - i - 1) / (num_algorithms - i - 1)\n",
    "      end = start + 2 * np.pi / (num_algorithms - i - 1)\n",
    "\n",
    "      theta = np.random.uniform(start, end, p.shape)\n",
    "      ax.scatter(theta, p, color='gray', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qb3kQb5j22iM"
   },
   "outputs": [],
   "source": [
    "def plot_top_k_probs(fig_name, model_names, algorithm_names, probs, empirical):\n",
    "  plotter = Plot()\n",
    "  num_samples, num_algorithms, _ = probs[0].shape\n",
    "  fig = plt.figure()\n",
    "  fig, axs = plt.subplots(len(model_names), num_algorithms, figsize=(4 * num_algorithms, 2 * len(model_names)), sharey=True)\n",
    "\n",
    "  plotter.plot_top_k_probs(model_names, algorithm_names, probs, empirical, axs)\n",
    "  fig.savefig(fig_name + \".pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAQ4hqM_Oq5C"
   },
   "source": [
    "#### Functions to calculate the empirical marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PQRAlm8mwqY"
   },
   "outputs": [],
   "source": [
    "def empirical_top_ranking_probs(orderings):\n",
    "  n, m =orderings.shape\n",
    "  probs = []\n",
    "\n",
    "  for i in range(m):\n",
    "    p_empirical = 0\n",
    "    for order in orderings:\n",
    "      if order[0] == i + 1:\n",
    "        p_empirical += 1\n",
    "    probs.append(p_empirical / n)\n",
    "\n",
    "  return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_jPdti3sUIO"
   },
   "outputs": [],
   "source": [
    "def empirical_better_than(orderings):\n",
    "  def indexOf(arr, elem):\n",
    "    for i, val in enumerate(arr):\n",
    "      if val == elem:\n",
    "        return i\n",
    "    return -1\n",
    "\n",
    "  n, m =orderings.shape\n",
    "  probs = np.zeros((n, m))\n",
    "\n",
    "  for i in range(m):\n",
    "    for j in range(m):\n",
    "      if i != j:\n",
    "        p_empirical = 0\n",
    "        for order in orderings:\n",
    "          if indexOf(order, i + 1) < indexOf(order, j + 1):\n",
    "            p_empirical += 1\n",
    "        probs[i, j] = p_empirical / n\n",
    "\n",
    "  return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mhRnfym3gYn"
   },
   "outputs": [],
   "source": [
    "def empirical_top_k(orderings):\n",
    "  def indexOf(arr, elem):\n",
    "    for i, val in enumerate(arr):\n",
    "      if val == elem:\n",
    "        return i\n",
    "    return -1\n",
    "\n",
    "  n, m =orderings.shape\n",
    "  probs = np.zeros((n, m))\n",
    "\n",
    "  for i in range(m):\n",
    "    for j in range(m):\n",
    "        p_empirical = 0\n",
    "        for order in orderings:\n",
    "          if indexOf(order, j + 1) <= i:\n",
    "            p_empirical += 1\n",
    "        probs[i, j] = p_empirical / n\n",
    "\n",
    "  return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JW7Ta3kGXrg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiK9h1jbOvVe"
   },
   "source": [
    "#### Functions to get insights on the empirical distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqWLh3cLOMQu"
   },
   "outputs": [],
   "source": [
    "def calculate_hist(rankings):\n",
    "  permus = []\n",
    "  count = []\n",
    "  m = len(rankings)\n",
    "\n",
    "  def equals(pi, eta):\n",
    "    for x, y in zip(pi, eta):\n",
    "      if x != y:\n",
    "        return False\n",
    "    return len(pi) == len(eta)\n",
    "\n",
    "  def isin(pi, list):\n",
    "    for eta in list:\n",
    "      if equals(pi, eta):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "  def indexOf(arr, elem):\n",
    "    for i, val in enumerate(arr):\n",
    "      if val == elem:\n",
    "        return i\n",
    "    return -1\n",
    "\n",
    "  def kendall(pi, eta):\n",
    "    pairs = itertools.combinations(set(pi + eta), 2)\n",
    "    distance = 0\n",
    "    for x, y in pairs:\n",
    "        a = indexOf(pi, x) - indexOf(pi, y)\n",
    "        b = indexOf(eta, x) - indexOf(eta, y)\n",
    "        if a * b < 0:\n",
    "            distance += 1\n",
    "    return distance\n",
    "\n",
    "  for i, pi in enumerate(rankings):\n",
    "    c = 1\n",
    "    if not isin(pi, permus):\n",
    "      for j in range(i + 1, m):\n",
    "        if equals(pi, rankings[j]):\n",
    "          c += 1\n",
    "    \n",
    "    permus.append(pi)\n",
    "    count.append(c)\n",
    "\n",
    "    mode_idx = np.argmax(count)\n",
    "    mode = permus[mode_idx]\n",
    "\n",
    "    n = 4\n",
    "    hist = []\n",
    "\n",
    "    for pi in rankings:\n",
    "      hist.append(kendall(list(pi), list(mode)))\n",
    "\n",
    "  return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-DMfde1OcNh"
   },
   "outputs": [],
   "source": [
    "def plot_hist(max_distance, hist, ax, title):\n",
    "  hist = np.array(hist)\n",
    "  count = []\n",
    "\n",
    "  for d in range(0, max_distance + 1):\n",
    "    count.append((hist == d).sum())\n",
    "\n",
    "  ax.bar(range(max_distance + 1), count, color='gray')\n",
    "  ax.set_title(title)\n",
    "  ax.set_xlabel('Distance to mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKsQ28DPzUii"
   },
   "source": [
    "### Syntetic Data Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pj8VgBhyPJ8o"
   },
   "source": [
    "#### Simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19JVvGdrGa0E"
   },
   "outputs": [],
   "source": [
    "def synthetic(num_instances, mean, std):\n",
    "  assert(len(mean) == len(std))\n",
    "\n",
    "  num_algorithms = len(mean)\n",
    "  scores = np.empty((num_instances, num_algorithms))\n",
    "  for i in range(num_instances):\n",
    "    for j in range(num_algorithms):\n",
    "      scores[i, j] = np.random.normal(mean[j], std[j])\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Jk8eA6PbjW8"
   },
   "outputs": [],
   "source": [
    "num_instances = 40\n",
    "mean = [2.0, 4.0, 6.0, 8.0]\n",
    "std  = [1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "scores = synthetic(num_instances, mean, std)\n",
    "orderings = np.argsort(scores, axis=1) + 1\n",
    "rankings = np.argsort(orderings, axis=1) + 1\n",
    "p_top_ranking = empirical_top_ranking_probs(orderings)\n",
    "p_better_than = empirical_better_than(orderings)\n",
    "p_top_k = empirical_top_k(orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNWGNR8nxYX0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1A0CskgFltHU"
   },
   "source": [
    "**Probability of an algorithm to be in the first ranking:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kB169eLxJJ_-"
   },
   "outputs": [],
   "source": [
    "probs = calculate_top_ranking_probs(orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wysquKERwocF"
   },
   "outputs": [],
   "source": [
    "plot_top_ranking_probs(fig_name='TopOneSynthetic', model_names=['PLD', 'PLG', 'BT', 'MM'], algorithm_names=['A1', 'A2', 'A3', 'A4'], probs=probs, empirical=p_top_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPESPszqlz-8"
   },
   "source": [
    "**Probability of an algorithm to be better than another:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ow3p7tAvky6v"
   },
   "outputs": [],
   "source": [
    "probs = calculate_better_than_probs(orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nPC1dhjk0x0"
   },
   "outputs": [],
   "source": [
    "plot_better_than_probs(fig_name='BetterThanSyntetic', model_names=['PLD', 'PLG', 'BT', 'MM'], algorithm_names=['A1', 'A2', 'A3', 'A4'], probs=probs, empirical=p_better_than)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xuzyeDhSg5b"
   },
   "outputs": [],
   "source": [
    "# BT\n",
    "plot_better_than_polar(4, probs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-VFKz02Tqjd"
   },
   "outputs": [],
   "source": [
    "# MM\n",
    "plot_better_than_polar(4, probs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_CJgDyYQZNXX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mz-Ki91e2sHq"
   },
   "source": [
    "**Probability of an algorithm to be in the top-k ranking:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHJJ1cAB2dXY"
   },
   "outputs": [],
   "source": [
    "probs = calculate_top_k_probs(orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3ujOdE454gc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAdI78622y9F"
   },
   "outputs": [],
   "source": [
    "plot_top_k_probs(fig_name='TopKSyntetic', model_names=['PLD', 'PLG', 'BT', 'MM'], algorithm_names=['A1', 'A2', 'A3', 'A4'], probs=probs, empirical=p_top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Luc8uS3HnjEt"
   },
   "source": [
    "#### Effect of multimodal distributions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-PEShpxQ0ck"
   },
   "source": [
    "**Generate empirical distributions using different standard deviations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHHgOpvEsIqF"
   },
   "outputs": [],
   "source": [
    "stds = [2.0, 4.0, 12.0]\n",
    "\n",
    "Lscores = []\n",
    "Lorderings = []\n",
    "Lrankings = []\n",
    "\n",
    "for i, std in enumerate(stds):\n",
    "  num_instances = 1000\n",
    "  mean = [2.0, 4.0, 6.0, 8.0]\n",
    "  std  = [std, 1.0, 1.0, std]\n",
    "\n",
    "  scores = synthetic(num_instances, mean, std)\n",
    "  orderings = np.argsort(scores, axis=1) + 1\n",
    "  rankings = np.argsort(orderings, axis=1) + 1\n",
    "\n",
    "  Lscores.append(scores)\n",
    "  Lorderings.append(orderings)\n",
    "  Lrankings.append(rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FPtXnIFQr61"
   },
   "source": [
    "**Histograms of the empirical distributions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWEjHk8msKWN"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(stds), figsize=(3 * len(stds), 2), sharey=True)\n",
    "\n",
    "for config, (rankings, ax) in enumerate(zip(Lrankings, axs)):\n",
    "  hist = calculate_hist(rankings)\n",
    "  plot_hist(6, hist, ax, title='Configuration ' + str(config + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-hYMiqRUjhD"
   },
   "outputs": [],
   "source": [
    "fig.savefig('hist.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izbYWAuRTWHh"
   },
   "source": [
    "Probability of an algorithm to be in the first ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIz4ZA0tTQsq"
   },
   "outputs": [],
   "source": [
    "probs_per_config = []\n",
    "for config, orderings in enumerate(Lorderings):\n",
    "  probs = calculate_top_ranking_probs(orderings)\n",
    "  probs_per_config.append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5T9txF2wWzXL"
   },
   "outputs": [],
   "source": [
    "for orderings, probs in zip(Lorderings, probs_per_config):\n",
    "  p_top_ranking = empirical_top_ranking_probs(orderings)\n",
    "  plot_top_ranking_probs(\"TopOneUnimodalSyntetic\", model_names=['PLD', 'PLG', 'BT', 'MM'], algorithm_names=['A1', 'A2', 'A3', 'A4'], probs=probs, empirical=p_top_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCk8B92gQJed"
   },
   "source": [
    "### EDA FSP Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGqD8qycJDyM"
   },
   "source": [
    "#### Preliminaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcvUxGyOl7fL"
   },
   "outputs": [],
   "source": [
    "!unzip -q FSPData.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HLA02Mn82Gbn"
   },
   "outputs": [],
   "source": [
    "def fix_index(df):\n",
    "  fixed_index = []\n",
    "  problems = []\n",
    "\n",
    "  for problem, rep in df.index:\n",
    "    if type(problem) == str:\n",
    "      problems.append(problem)\n",
    "      prev = problem\n",
    "    fixed_index.append((prev, rep))\n",
    "\n",
    "  fixed_index = pd.MultiIndex.from_tuples(fixed_index)\n",
    "  return fixed_index, problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BzPQr3M8UuV"
   },
   "outputs": [],
   "source": [
    "def ranks_from_score(score):\n",
    "  # Set of linear extensions of the original ranking. The linear extensions are\n",
    "  # obtained when ties are resolved in all possible ways.\n",
    "  permus = []\n",
    "  weights = []\n",
    "\n",
    "  n = len(score)\n",
    "  rank = np.argsort(score)\n",
    "\n",
    "  # List that contains several lists that represent element's index that are \n",
    "  # repeated in the original score.\n",
    "  #\n",
    "  # For example, if there is a single list with two elements, e.g. [[3, 6]] it\n",
    "  # means that `score[3] == score[6].\n",
    "  ties_set = []\n",
    "  excluded = []\n",
    "  \n",
    "  # Loop through all elements in score.\n",
    "  for i in range(n):\n",
    "    if i not in excluded:\n",
    "      repeated = [i]\n",
    "\n",
    "      # Check if there are any ties in the rest of the score list.\n",
    "      for j in range(i + 1, n):\n",
    "\n",
    "        # If there is a tie, then add the entry to the repeated list.\n",
    "        if score[i] == score[j]:\n",
    "          repeated.append(j)\n",
    "\n",
    "      excluded += repeated\n",
    "      \n",
    "      # If there is any tie, then, add it to the tie set.\n",
    "      if len(repeated) > 1:\n",
    "        ties_set.append(repeated)\n",
    "\n",
    "  # List that contains several lists that represent the elements index that are \n",
    "  # repeated in the original score and all their permutations. \n",
    "  #\n",
    "  # For example, if there is a single list with two elements, it means that there \n",
    "  # is a single repeated element that appears three times in the original score.\n",
    "  #\n",
    "  # If there are two lists with three elements each, it means that there are two\n",
    "  # repeated elements that appear three times each in the original score.\n",
    "  #\n",
    "  # The values within each list inside this list represent the rankings of such\n",
    "  # repeated entries.\n",
    "  extensions = []\n",
    "  for i, repeated in enumerate(ties_set):\n",
    "    extensions.append(list(itertools.permutations(repeated)))\n",
    "  extensions = list(itertools.product(*extensions))\n",
    "\n",
    "  # Loop through all possible linear extensions.\n",
    "  for extension in extensions:\n",
    "    # Start to modify the original ranking to create the linear extension.\n",
    "    permu = rank\n",
    "\n",
    "    # Swap the rankings of the repeated / tie scores iteratively.\n",
    "    for section in extension:\n",
    "      # Size of the section to be replaced.\n",
    "      sec_size = len(section)\n",
    "      \n",
    "      # Determine the starting point in ranking in which we replace\n",
    "      # the section.\n",
    "      for start, value in enumerate(permu):\n",
    "        if value in section:\n",
    "          break\n",
    "      \n",
    "      # Modify the original ranking iteratively.\n",
    "      permu = np.concatenate((permu[:start], section, permu[start + sec_size:]))\n",
    "\n",
    "    # Add the linear extension to the permutation set.\n",
    "    permus.append(permu + 1)\n",
    "    weights.append(1.0 / len(extensions))\n",
    "\n",
    "  return permus, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BHaItMW5HFk"
   },
   "outputs": [],
   "source": [
    "def load_permus_from_file(prefix, algorithms, num_instances=10, num_reps=20):\n",
    "  permus = []\n",
    "  scores = []\n",
    "  problems = []\n",
    "  weights = [] \n",
    "  dfs = [pd.read_csv(prefix + '-' + algorithm + '.csv', header=[0], \n",
    "                     index_col=[0,1]) for algorithm in algorithms]\n",
    "\n",
    "  for df in dfs:\n",
    "    index, problems = fix_index(df)\n",
    "    df.index = index\n",
    "    df = df.astype(int)\n",
    "\n",
    "  for i, problem in enumerate(problems):\n",
    "      for instance in range(num_instances):\n",
    "        for rep in range(num_reps):\n",
    "          # Score of each algorithm.\n",
    "          score = []\n",
    "\n",
    "          for df in dfs:\n",
    "            # Locate the score for each algorithm per problem / instance / rep.\n",
    "            score.append(df.loc[(problem, str(rep + 1)), str(instance)])\n",
    "            # Obtain the rankings, including linear extensions.\n",
    "          \n",
    "          p, w = ranks_from_score(score)\n",
    "          scores.append(score)\n",
    "\n",
    "          permus += p\n",
    "          weights += w\n",
    "\n",
    "  return np.array(permus), np.array(weights), np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRYjFj2iQXgJ"
   },
   "outputs": [],
   "source": [
    "def sample_permus(permus, weights, num_samples):\n",
    "  n = len(weights)\n",
    "  sample_permus = []\n",
    "  sample_weights = []\n",
    "\n",
    "  while True:\n",
    "    idx = np.random.randint(0, n)\n",
    "\n",
    "    permu = permus[idx]\n",
    "    w = weights[idx]\n",
    "\n",
    "    if np.random.random() < w:\n",
    "      sample_permus.append(permu)\n",
    "      sample_weights.append(w)\n",
    "\n",
    "      if len(sample_weights) == num_samples:\n",
    "        return np.array(sample_permus), np.array(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKcZVLN3QXlx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6V1_vvOWRSR_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "At0AEgOHV22u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvSKSYLEMU4v"
   },
   "source": [
    "### Joint Taillard + Random instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAiTL2rMMYCo"
   },
   "outputs": [],
   "source": [
    "algorithms = ['A', 'B', 'AGA', 'VNS', 'NVNS']\n",
    "orderingsT, weightsT, scoresT = load_permus_from_file('FSPData/T', algorithms)\n",
    "orderingsR, weightsR, scoresR = load_permus_from_file('FSPData/R', algorithms)\n",
    "\n",
    "orderings = np.concatenate((orderingsT, orderingsR), axis=0)\n",
    "weights = np.concatenate((weightsT, weightsR))\n",
    "\n",
    "orderings, weights = sample_permus(orderings, weights, 100)\n",
    "rankings = np.argsort(orderings, axis=1) + 1\n",
    "p_top_ranking = empirical_top_ranking_probs(orderings)\n",
    "p_better_than = empirical_better_than(orderings)\n",
    "p_top_k = empirical_top_k(orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlwylS6QVLiT"
   },
   "outputs": [],
   "source": [
    "p_top_k = empirical_top_k(orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4v1arP4NLZA"
   },
   "outputs": [],
   "source": [
    "probs = calculate_top_ranking_probs(orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06AvzaRnNL1o"
   },
   "outputs": [],
   "source": [
    "plot_top_ranking_probs(\"TopOneTaillardRI\", model_names=['PLD', 'PLG', 'BT', 'MM'], algorithm_names=algorithms, probs=probs, empirical=p_top_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYjHMB_ENO3F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkmAqezKNO5y"
   },
   "outputs": [],
   "source": [
    "probs = calculate_better_than_probs(orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBCGPBZONQvF"
   },
   "outputs": [],
   "source": [
    "plot_better_than_probs(\"BetterThanTaillardRI\", model_names=['PLD', 'PLG', 'BT', 'MM'], algorithm_names=algorithms, probs=probs, empirical=p_better_than)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EiHXVlPgLl3U"
   },
   "outputs": [],
   "source": [
    "plot_better_than_polar(5, algorithms, probs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8PcG53XLsdy"
   },
   "outputs": [],
   "source": [
    "plot_better_than_polar(5, algorithms, probs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GVfC3xFbde7"
   },
   "outputs": [],
   "source": [
    "probs = calculate_top_k_probs(orderings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sK--qo8gbgmp"
   },
   "outputs": [],
   "source": [
    "plot_top_k_probs(\"TopKTaillardRI\", model_names=['PLD', 'PLG', 'BT', 'MM'], algorithm_names=algorithms, probs=probs, empirical=p_top_k)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YmC9p4Xvqfp-",
    "Qm3_SsZdz6jV",
    "8ls9oVkvOfRp",
    "DrR1gqx_OlCL",
    "TAQ4hqM_Oq5C",
    "OiK9h1jbOvVe",
    "GKsQ28DPzUii",
    "OCk8B92gQJed",
    "kGqD8qycJDyM"
   ],
   "name": "Copy of BayesPerm-PresentationCode.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
